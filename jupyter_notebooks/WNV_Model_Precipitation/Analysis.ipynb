{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WNV Model - NARR Precipitation Data Analysis\n",
    "In this notebook we will calculate various indices for the urban counties using the [precipitation dataset from NARR](https://www.esrl.noaa.gov/psd/data/gridded/data.narr.html).\n",
    "\n",
    "The years we will calculate these values across will be 1999-2015.\n",
    "\n",
    "The summer period is defined as June 1st to August 1st.\n",
    "\n",
    "A dry day is defined as less than 0.0393701 inches (1mm) of precipitation.\n",
    "\n",
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "import pysal\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Ratio of Peak to Average Rainfall\n",
    "We will calculate the maximal and mean rainfall over this 61 day period for each county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open('./county_data/ratio.csv', 'w')\n",
    "writer = csv.writer(outfile, delimiter=',')\n",
    "\n",
    "# CSV Header\n",
    "writer.writerow(['Year', 'County Name', 'GEOID', 'Ratio of Max to Mean'])\n",
    "\n",
    "frame = pd.read_pickle(output_dir + '1999.pkl')\n",
    "frame['max'] = frame.max(axis=1)\n",
    "frame['mean'] = frame.mean(axis=1)\n",
    "frame['ratio'] = round(frame['max'] / frame['mean'], 4)\n",
    "all_data = (frame.iloc[:,0].to_frame().join(frame.iloc[:,-1]))\n",
    "cols = all_data.columns.values\n",
    "cols[-1] = '1999'\n",
    "all_data.columns = cols\n",
    "\n",
    "for year in range(2000, 2016):\n",
    "    frame = pd.read_pickle(output_dir + str(year) + '.pkl')\n",
    "    \n",
    "    # Max over 62 days of each county\n",
    "    frame['max'] = frame.max(axis=1)\n",
    "    # Mean over 62 days of each county\n",
    "    frame['mean'] = frame.mean(axis=1)\n",
    "    #Ratio of Max to Mean\n",
    "    frame['ratio'] = round(frame['max'] / frame['mean'], 4)\n",
    "    \n",
    "    data = (frame.iloc[:,-1].to_frame())\n",
    "    \n",
    "    cols = data.columns.values\n",
    "    cols[-1] = str(year)\n",
    "    data.columns = cols\n",
    "    \n",
    "    all_data = all_data.join(data)\n",
    "\n",
    "all_data.to_csv('./county_data/ratio.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Max Ratio\n",
    "\n",
    "This will create a spreadsheet of the maximum ratios along with the ratios within 5% of the maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open('./county_data/max_ratio.csv', 'w')\n",
    "writer = csv.writer(outfile, delimiter=',')\n",
    "\n",
    "for year in range(1999, 2016):\n",
    "    frame = pd.read_pickle(output_dir + str(year) + '.pkl')\n",
    "    \n",
    "    # Max over 62 days of each county\n",
    "    frame['max'] = frame.max(axis=1)\n",
    "    # Mean over 62 days of each county\n",
    "    frame['mean'] = frame.mean(axis=1)\n",
    "    #Ratio of Max to Mean\n",
    "    frame['ratio'] = round(frame['max'] / frame['mean'], 4)\n",
    "    \n",
    "    # Obtain and write max ratio's data\n",
    "    max_id = frame['ratio'].idxmax()\n",
    "    max_ratio = frame['ratio'].max()\n",
    "    name = frame['NAME'].loc[int(max_id)]\n",
    "    \n",
    "    if len(str(max_id)) < 5:\n",
    "        max_id = int('0' + str(max_id))\n",
    "    writer.writerow([year, name, max_id, max_ratio])\n",
    "\n",
    "    # Get all ratios within 5% of the max ratio\n",
    "    diff = max_ratio * 0.05\n",
    "    max_ratios = frame.loc[(max_ratio - diff < frame['ratio'])]\n",
    "    for geoid in max_ratios.index:\n",
    "        if geoid != max_id:\n",
    "            data = max_ratios.loc[geoid]\n",
    "            writer.writerow([year, data['NAME'], geoid, data['ratio']])\n",
    "            \n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Counting Dry Days Over The Period\n",
    "\n",
    "We will convert the data to two spreadsheets:\n",
    "\n",
    "1) The count of dry days over the period of June 1st to August 1st\n",
    "\n",
    "2) The percentage of dry days over the period (dry days / total days)\n",
    "\n",
    "We define a dry day as 0 inches of rainfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base frame with Year 1999\n",
    "frame = pd.read_pickle(output_dir + '1999.pkl')\n",
    "frame.index = frame.index.apply(lambda x: x if len(x) < 6 )\n",
    "zeroes = frame.isin([0])\n",
    "zeroes = zeroes.sum(1)\n",
    "zeroes = zeroes.to_frame()\n",
    "\n",
    "# Change column to 1999\n",
    "cols = zeroes.columns.values\n",
    "cols[0] = '1999'\n",
    "zeroes.columns = cols\n",
    "\n",
    "# Create the dataframe\n",
    "data = frame.iloc[:,:1].join(zeroes)\n",
    "# print(data)\n",
    "\n",
    "for year in range(2000, 2016):\n",
    "    frame = pd.read_pickle(output_dir + str(year) + '.pkl')\n",
    "    zeroes = frame.isin([0])\n",
    "    zeroes = zeroes.sum(1)\n",
    "    zeroes = zeroes.to_frame()\n",
    "    \n",
    "    cols = zeroes.columns.values\n",
    "    cols[0] = str(year)\n",
    "    zeroes.columns = cols\n",
    "    \n",
    "    data = data.join(zeroes)\n",
    "\n",
    "num_days = len(frame.columns[1:])\n",
    "\n",
    "percent_data = data.iloc[:,1:]\n",
    "percent_data = percent_data.apply(lambda x: round(x / num_days * 100, 4))\n",
    "percent_data = frame['NAME'].to_frame().join(percent_data)\n",
    "\n",
    "\n",
    "percent_data.to_csv('./county_data/dry_days_percentage.csv')\n",
    "data.to_csv('./county_data/dry_days.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Shannon's Entropy\n",
    "\n",
    "We will calculate Shannon's entropy over this 62 day period for each year. \n",
    "\n",
    "Since Shannon's entropy requires a discrete distribution, we will bin the data into 10 bins before calculating the entropy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open('./county_data/shannons_entropy.csv', 'w')\n",
    "writer = csv.writer(outfile, delimiter=',')\n",
    "writer.writerow(['Year', 'Dry 8 Bins', 'Dry 12 Bins', 'Wet 8 Bins', 'Wet 12 Bins'])\n",
    "\n",
    "for year in range(1999, 2016):\n",
    "    frame = pd.read_pickle(output_dir + str(year) + '.pkl')\n",
    "    \n",
    "    num_days = len(frame.columns[1:])\n",
    "    \n",
    "    probability_frame = (frame.isin([0]).sum(1).to_frame())\n",
    "    \n",
    "    dry_frame = frame.isin([0]).sum(1).to_frame()  # Number of Dry Days (count of 0's)\n",
    "    wet_frame = num_days-dry_frame  # Number of wet days (total days - dry days)\n",
    "    \n",
    "    dry_prob = probability_frame.apply(lambda x: (x / num_days))  # Probability of a dry day\n",
    "    wet_prob = probability_frame.apply(lambda x: 1 - (x/num_days))  \n",
    "    \n",
    "    #Binning Dry Probability - 8 Bins\n",
    "    dry_prob['bin'] = pd.cut(dry_prob.iloc[:,0], 8)\n",
    "    dry_prob_bin = dry_prob.groupby(dry_prob['bin']).size()\n",
    "\n",
    "    #Binning Wet Probability - 8 Bins\n",
    "    wet_prob['bin'] = pd.cut(wet_prob.iloc[:,0],8)\n",
    "    wet_prob_bin = wet_prob.groupby(wet_prob['bin']).size()\n",
    "    \n",
    "    # Binning Dry Days - 8 Bins\n",
    "    dry_frame['bin'] = pd.cut(dry_frame.iloc[:,0],8)\n",
    "    dry_days_bin = dry_frame.groupby(dry_frame['bin']).size()\n",
    "    \n",
    "    # Binning Wet Days - 8 Bins\n",
    "    wet_frame['bin'] = pd.cut(wet_frame.iloc[:,0],8)\n",
    "    wet_days_bin = wet_frame.groupby(wet_frame['bin']).size()\n",
    "    \n",
    "    \n",
    "    # Repeating with 12 bins (one for each month of the year)\n",
    "    \n",
    "    dry_prob = probability_frame.apply(lambda x: (x / num_days))  # Probability of a dry day\n",
    "    wet_prob = probability_frame.apply(lambda x: 1 - (x/num_days))  \n",
    "    \n",
    "    #Binning Dry Probability - 12 Bins\n",
    "    dry_prob['bin'] = pd.cut(dry_prob.iloc[:,0], 12)\n",
    "    dry_prob_bin_12 = dry_prob.groupby(dry_prob['bin']).size()\n",
    "\n",
    "    #Binning Wet Probability - 12 Bins\n",
    "    wet_prob['bin'] = pd.cut(wet_prob.iloc[:,0],12)\n",
    "    wet_prob_bin_12 = wet_prob.groupby(wet_prob['bin']).size()\n",
    "    \n",
    "    # Binning Dry Days - 12 Bins\n",
    "    dry_frame['bin'] = pd.cut(dry_frame.iloc[:,0],12)\n",
    "    dry_days_bin_12 = dry_frame.groupby(dry_frame['bin']).size()\n",
    "    \n",
    "    # Binning Wet Days - 12 Bins\n",
    "    wet_frame['bin'] = pd.cut(wet_frame.iloc[:,0],12)\n",
    "    wet_days_bin_12 = wet_frame.groupby(wet_frame['bin']).size()\n",
    "    \n",
    "    \n",
    "#     print(entropy(wet_days_bin), entropy(wet_prob_bin), entropy(dry_days_bin), entropy(dry_prob_bin))\n",
    "    \n",
    "    writer.writerow([year, entropy(dry_days_bin), entropy(dry_days_bin_12), entropy(wet_days_bin), entropy(wet_days_bin_12)])\n",
    "outfile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Gini and Theil Coefficients for Summer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(1999, 2016):\n",
    "    \n",
    "    frame = pd.read_pickle('./county_data/dataframes/summer_data/' + str(year) + '.pkl')\n",
    "    frame = frame.reset_index()    \n",
    "    name = frame.iloc[:,1]\n",
    "    frame = frame.drop('NAME', axis=1)\n",
    "\n",
    "    if year == 1999:        \n",
    "        gini = pd.DataFrame(index=frame.index)\n",
    "        gini = gini.join(name)\n",
    "        \n",
    "        theil = pd.DataFrame(index=frame.index)\n",
    "        theil = theil.join(name)\n",
    "    \n",
    "    gini_frame = frame.apply(pysal.explore.inequality.gini.Gini, axis=1).apply(lambda x: x.g)\n",
    "    theil_frame = frame.apply(pysal.explore.inequality.theil.Theil, axis=1).apply(lambda x: x.T)\n",
    "    \n",
    "    gini = gini.join(gini_frame.to_frame(str(year)))\n",
    "    theil = theil.join(theil_frame.to_frame(str(year)))\n",
    "       \n",
    "gini.set_index(frame['GEOID'], drop=True, inplace=True)\n",
    "theil.set_index(frame['GEOID'], drop=True, inplace=True)\n",
    "\n",
    "gini.to_csv('./county_data/gini/gini_index_summer.csv')\n",
    "theil.to_csv('./county_data/theil/theil_index_summer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Gini and Theil Coefficient over Entire Dataset\n",
    "We will calculate the Gini and Theil coefficient for each county over each year using [pysal's implementation](https://pysal.readthedocs.io/en/v1.12.0/library/inequality/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Coefficients on Unfiltered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(1999, 2016):\n",
    "    frame = pd.read_pickle('./county_data/dataframes/all_data/' + str(year) + '.pkl')  # Load the data\n",
    "    name = frame.iloc[:,0]\n",
    "    data = frame.iloc[:,1:]  # Ignore the NAME column\n",
    "    \n",
    "    if year == 1999:\n",
    "        gini = pd.DataFrame(index=frame.index)\n",
    "        gini = gini.join(name)\n",
    "        \n",
    "        theil = pd.DataFrame(index=frame.index)\n",
    "        theil = theil.join(name)\n",
    "\n",
    "    gini_data = data.apply(pysal.explore.inequality.gini.Gini, axis=1).apply(lambda x: x.g)\n",
    "    theil_data = data.apply(pysal.explore.inequality.theil.Theil, axis=1).apply(lambda x: x.T)\n",
    "    \n",
    "    \n",
    "    gini = gini.join(gini_data.to_frame(str(year)))\n",
    "    theil = theil.join(theil_data.to_frame(str(year)))\n",
    "  \n",
    "\n",
    "gini.to_csv('./county_data/gini/gini_index.csv')\n",
    "theil.to_csv('./county_data/theil/theil_index.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(1999, 2016):\n",
    "    frame = pd.read_pickle('./county_data/dataframes/filtered_freezing_data/' + str(year) + '.pkl')  # Load the data\n",
    "    data = frame.iloc[:,1:]  # Ignore the NAME column\n",
    "    \n",
    "    if year == 1999:\n",
    "        gini = pd.DataFrame(index=frame.index)\n",
    "        gini = gini.join(name)\n",
    "        \n",
    "        theil = pd.DataFrame(index=frame.index)\n",
    "        theil = theil.join(name)\n",
    "    \n",
    "    gini_data = data.apply(pysal.explore.inequality.gini.Gini, axis=1).apply(lambda x: x.g)\n",
    "    theil_data = data.apply(pysal.explore.inequality.theil.Theil, axis=1).apply(lambda x: x.T)\n",
    "    \n",
    "    gini = gini.join(gini_data.to_frame(str(year)))\n",
    "    theil = theil.join(theil_data.to_frame(str(year)))\n",
    "    \n",
    "    \n",
    "gini.to_csv('./county_data/gini/gini_index_filtered.csv')\n",
    "theil.to_csv('./county_data/theil/theil_index_filtered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Aggregated Precipitation\n",
    "\n",
    "We will calculate the total precipitation (both filtered and unfiltered) across each year for each county.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = './county_data/aggregated/'\n",
    "if not os.path.exists(out_dir):\n",
    "    print('Making', out_dir)\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unfiltered Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_pickle('./county_data/dataframes/all_data/1999.pkl').set_index('GEOID', drop=True)\n",
    "name = frame.iloc[:, 0]\n",
    "frame = frame.iloc[:,1:].sum(axis=1)\n",
    "frame = frame.to_frame('1999')\n",
    "\n",
    "for year in range(2000,2016):\n",
    "    sub_frame = pd.read_pickle('./county_data/dataframes/all_data/' + str(year) + '.pkl').set_index('GEOID', drop=True)\n",
    "    sub_frame = sub_frame.sum(axis=1).rename(str(year))\n",
    "    frame = frame.join(sub_frame)\n",
    "\n",
    "frame = name.to_frame().join(frame)\n",
    "frame.to_csv('./county_data/aggregated/unfiltered_aggregated_precipitation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtered Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_pickle('./county_data/dataframes/filtered_freezing_data/1999.pkl')\n",
    "name = frame.iloc[:, 0]\n",
    "frame = frame.iloc[:,1:].sum(axis=1)\n",
    "frame = frame.to_frame('1999')\n",
    "\n",
    "for year in range(2000,2016):\n",
    "    sub_frame = pd.read_pickle('./county_data/dataframes/filtered_freezing_data/' + str(year) + '.pkl')\n",
    "    sub_frame = sub_frame.sum(axis=1).rename(str(year))\n",
    "    frame = frame.join(sub_frame)\n",
    "    \n",
    "frame = name.to_frame().join(frame)\n",
    "frame.to_csv('./county_data/aggregated/filtered_aggregated_precipitation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Count of Total Dry Days\n",
    "\n",
    "We consider a dry day to be where the precipitation is less than 0.0393701 inches (1 millimeter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Filtered Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_pickle('./county_data/dataframes/filtered_freezing_data/1999.pkl')\n",
    "name = frame.iloc[:,0].to_frame('NAME')\n",
    "data = frame.iloc[:,1:]  # Ignore the NAME column\n",
    "\n",
    "dry_days = data < 0.0393701  # True if Dry, False if Wet\n",
    "dry_days = dry_days.applymap(lambda x: -1 if x is False else 1)  # Replace false with -1, true with 1\n",
    "\n",
    "data = data * dry_days  # Wet days will have a negative value\n",
    "data = data.applymap(lambda x: np.nan if x < 0 else x)  # Wet days and freezing days will be NaN\n",
    "\n",
    "# Count the number of remaining values across each row\n",
    "frame = data.count(axis=1).to_frame('1999')\n",
    "\n",
    "frame = name.join(frame)\n",
    "\n",
    "for year in range(2000, 2016):\n",
    "    subframe = pd.read_pickle('./county_data/dataframes/filtered_freezing_data/' + str(year) + '.pkl')\n",
    "    data = subframe.iloc[:,1:]  # Ignore the NAME column\n",
    "    dry_days = data < 0.0393701  # True if Dry, False if Wet\n",
    "    \n",
    "    dry_days = dry_days.applymap(lambda x: -1 if x is False else 1)  # Replace false with -1, true with 1\n",
    "    \n",
    "    data = data * dry_days  # Wet days will have a negative value\n",
    "    data = data.applymap(lambda x: np.nan if x < 0 else x)  # Wet days and freezing days will be NaN\n",
    "    \n",
    "    # Count the number of remaining values across each row\n",
    "    data = data.count(axis=1).to_frame(str(year))\n",
    "    frame = frame.join(data)\n",
    "    \n",
    "frame.to_csv('./county_data/dry/dry_days_filtered.csv')\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Unfiltered Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_pickle('./county_data/dataframes/all_data/1999.pkl')\n",
    "name = frame.iloc[:,0].to_frame('NAME')\n",
    "data = frame.iloc[:,1:]  # Ignore the NAME column\n",
    "\n",
    "dry_days = data < 0.0393701  # True if Dry, False if Wet\n",
    "dry_days = dry_days.applymap(lambda x: -1 if x is False else 1)  # Replace false with -1, true with 1\n",
    "\n",
    "data = data * dry_days  # Wet days will have a negative value\n",
    "data = data.applymap(lambda x: np.nan if x < 0 else x)  # Wet days and freezing days will be NaN\n",
    "\n",
    "# Count the number of remaining values across each row\n",
    "frame = data.count(axis=1).to_frame('1999')\n",
    "frame = name.join(frame)\n",
    "\n",
    "for year in range(2000, 2016):\n",
    "    subframe = pd.read_pickle('./county_data/dataframes/all_data/' + str(year) + '.pkl')\n",
    "    data = subframe.iloc[:,1:]  # Ignore the NAME column\n",
    "    dry_days = data < 0.0393701  # True if Dry, False if Wet\n",
    "    \n",
    "    dry_days = dry_days.applymap(lambda x: -1 if x is False else 1)  # Replace false with -1, true with 1\n",
    "    \n",
    "    data = data * dry_days  # Wet days will have a negative value\n",
    "    data = data.applymap(lambda x: np.nan if x < 0 else x)  # Wet days and freezing days will be NaN\n",
    "    \n",
    "    # Count the number of remaining values across each row\n",
    "    data = data.count(axis=1).to_frame(str(year))\n",
    "    frame = frame.join(data)\n",
    "    \n",
    "frame.to_csv('./county_data/dry/dry_days_unfiltered.csv')\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Maximum Consecutive Dry Days\n",
    "\n",
    "We will find the longest chain of consecutive dry days for each county over each year.\n",
    "\n",
    "We consider a dry day to be where the precipitation is less than 0.0393701 inches (1 millimeter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive_days(row):\n",
    "#     num_days = 3\n",
    "    consecutive = row * (row.groupby((row != row.shift()).cumsum()).cumcount()+1)\n",
    "    return consecutive.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = pd.read_pickle('./county_data/dataframes/filtered_freezing_data/1999.pkl').iloc[:,0].to_frame()\n",
    "\n",
    "for year in range(1999, 2016):\n",
    "    frame = pd.read_pickle('./county_data/dataframes/filtered_freezing_data/' + str(year) + '.pkl')\n",
    "    data = frame.iloc[:,1:]\n",
    "    dry_days = data < 0.0393701  # True if Dry, False if Wet\n",
    "    \n",
    "    consecutive = dry_days.apply(consecutive_days, axis=1).to_frame(str(year))\n",
    "    name = name.join(consecutive)\n",
    "\n",
    "name.to_csv('./county_data/dry/max_consecutive_dry_days.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Gini and Theil Inequality on Weekly Aggregated Data\n",
    "\n",
    "We will sum the precipitation across each week, and calculate the gini and theil inequality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day = {\n",
    "             1999:'Thu', 2000:'Sat', 2001:'Sun', 2002:'Mon', 2003:'Tue', \n",
    "             2004:'Wed', 2005:'Fri', 2006:'Sat', 2007:'Sun', 2008:'Mon', \n",
    "             2009:'Wed', 2010:'Thu', 2011:'Fri', 2012:'Sat', 2013:'Mon',\n",
    "             2014:'Tue', 2015:'Wed',\n",
    "            }\n",
    "\n",
    "for year in range(1999, 2016):    \n",
    "    frame = pd.read_pickle('./county_data/dataframes/all_data/datetime_headers/' + str(year) + '.pkl')\n",
    "    name = frame.iloc[:, 0]\n",
    "\n",
    "    if year == 1999:\n",
    "        gini = pd.DataFrame(index=frame.index)\n",
    "        gini = gini.join(name)\n",
    "        \n",
    "        theil = pd.DataFrame(index=frame.index)\n",
    "        theil = theil.join(name)\n",
    "        \n",
    "    data = frame.iloc[:,2:]\n",
    "\n",
    "    # Pickling the frame doesn't preserve column datatype (datetime), so we have to reconvert anyways\n",
    "    data.columns = pd.to_datetime(data.columns)\n",
    "    \n",
    "    weekly = data.resample('W-'+first_day[year], axis=1).sum()\n",
    "\n",
    "    gini_data = weekly.apply(pysal.explore.inequality.gini.Gini, axis=1).apply(lambda x: x.g).rename(year)\n",
    "    theil_data = weekly.apply(pysal.explore.inequality.theil.Theil, axis=1).apply(lambda x: x.T).rename(year)\n",
    "    \n",
    "    gini = gini.join(gini_data)\n",
    "    theil = theil.join(theil_data)\n",
    "    \n",
    "gini.to_csv('./county_data/gini/gini_weekly.csv')\n",
    "theil.to_csv('./county_data/theil/theil_weekly.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
