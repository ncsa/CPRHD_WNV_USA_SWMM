{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Evaporation Data for each Year\n",
    "We will obtain the evaporation data for each month for each year across each blockgroup. This will then be implemented in the input file as a Timeseries\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'evap.mon.mean.nc'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'ftp://ftp.cdc.noaa.gov/Datasets/NARR/Monthlies/monolevel/evap.mon.mean.nc'\n",
    "\n",
    "wget.download(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert NetCDF to GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_5070 = '+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +towgs84=1,1,-1,0,0,0,0 +units=m +no_defs'\n",
    "warp_options = gdal.WarpOptions(options = '-t_srs \\\"' + projection_5070 + '\\\" -of GTiff')\n",
    "\n",
    "ds = gdal.Warp('./evap.mon.mean.geotiff', 'NETCDF:./evap.mon.mean.nc:evap', options=warp_options)\n",
    "ds = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the Bands of the GeoTIFF\n",
    "\n",
    "The NetCDF data starts recording from January 1979 (Band 1). We only want the data from January 1981 to December 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = './geotiffs/geotiffs/'\n",
    "if not os.path.exists(out_dir):\n",
    "    print('Making', out_dir)\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 25\n",
      "End: 432\n"
     ]
    }
   ],
   "source": [
    "start_year = 1981\n",
    "start_month = 1\n",
    "end_year = 2014\n",
    "end_month = 12\n",
    "\n",
    "start_band = (start_year - 1979) * 12 + start_month\n",
    "end_band = (end_year - 1979) * 12 + end_month\n",
    "print('Start:', start_band)\n",
    "print('End:', end_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 408/408 [00:25<00:00, 16.30it/s]\n"
     ]
    }
   ],
   "source": [
    "in_ds = gdal.Open('./evap.mon.mean.geotiff')\n",
    "\n",
    "for band in tqdm(range(start_band, end_band+1)):\n",
    "    outfile = out_dir + str(band) + '.geotiff'\n",
    "    \n",
    "    translate_options = gdal.TranslateOptions(options='-b ' + str(band) + ' -of GTiff')\n",
    "    gdal.Translate(outfile, in_ds, options=translate_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some block groups lie in the ocean, this will cause incorrect evaporation data for them as the oceans have higher evaporation rates.\n",
    "\n",
    "<img src=\"https://i.imgur.com/F6UIyls.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masking the GeoTIFFs\n",
    "To solve this issue, we will mask the evaporation data using the land mask provided by NARR NCEP.\n",
    "\n",
    "##### Download the Land Mask File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'land.nc'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'ftp://ftp.cdc.noaa.gov/Datasets/NARR/time_invariant/land.nc'\n",
    "wget.download(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Project the Land Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_5070 = '+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +towgs84=1,1,-1,0,0,0,0 +units=m +no_defs'\n",
    "warp_options = gdal.WarpOptions(options = '-t_srs \\\"' + projection_5070 + '\\\" -of GTiff')\n",
    "\n",
    "ds = gdal.Warp('./land.geotiff', 'NETCDF:./land.nc:land', options=warp_options)\n",
    "ds = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Gdal_calc.py\n",
    "This will be used to mask the files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdal_path = '/home/matas/anaconda3/envs/swmm/bin/'\n",
    "sys.path.insert(0, gdal_path)\n",
    "import gdal_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = './geotiffs/masked_geotiffs/'\n",
    "if not os.path.exists(out_dir):\n",
    "    print('Making', out_dir)\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_mask = './land.geotiff'\n",
    "\n",
    "for geotiff in glob.glob('./geotiffs/geotiffs/*.geotiff'):\n",
    "    print(band_number)\n",
    "    band_number = geotiff[geotiff.rfind('/')+1:geotiff.rfind('.')]\n",
    "    outfile = out_dir + band_number + '.geotiff'\n",
    "    \n",
    "    gdal_calc.Calc('A*B', A=geotiff, B=land_mask, outfile=outfile, format='GTiff', NoDataValue=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the block groups that were affected have NoData, since we specified NoData = 0.\n",
    "<img src=\"https://i.imgur.com/povTQzI.png\">\n",
    "\n",
    "We will interpolate this missing data from data values around the missing data pixels, extending the raster by one pixel in each direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Interpolation\n",
    "\n",
    "We will interpolate the data in a 3x3 grid around the target pixel. We will only modify a pixel if it has no data, and if it has at least one neighbor with data.\n",
    "\n",
    "Neighbors directly adjacent to the target pixel (North, East, South, West) will receive a weight of 1.\n",
    "\n",
    "Neighbors diagonally adjacent to the target pixel (NW, NE, SE, SW) will receive a weight of $\\dfrac{1}{\\sqrt{2}}$, since they are farther. Note that each pixel in this dataset represents about 32km$^{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = './geotiffs/masked_extended_geotiffs/'\n",
    "if not os.path.exists(out_dir):\n",
    "    print('Making', out_dir)\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import numpy as np\n",
    "\n",
    "for geotiff in glob.glob('./geotiffs/masked_geotiffs/*.geotiff'):\n",
    "    name = geotiff[geotiff.rfind('/')+1:geotiff.rfind('.')]\n",
    "    print(name)\n",
    "    raster = rio.open(geotiff)\n",
    "    data = raster.read(1)\n",
    "    \n",
    "    rows = data.shape[0]\n",
    "    cols = data.shape[1]\n",
    "    nodata = raster.nodatavals\n",
    "    data = np.ma.masked_equal(data, nodata)\n",
    "    output = np.copy(data)\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if data.mask[i][j]:\n",
    "                try:\n",
    "                    total = 0\n",
    "                    count = 0\n",
    "                    for x in range(-1,2):\n",
    "                        for y in range(-1,2):\n",
    "                            if not data.mask[i+x][j+y]:\n",
    "                                if (x == -1 or x == 1) and (y == -1 or y == 1):\n",
    "                                    total += data[i+x][j+y] / 1.41421356237\n",
    "                                else:\n",
    "                                    total += data[i+x][j+y]\n",
    "                                count+= 1\n",
    "                                \n",
    "                    output[i][j] = total / count\n",
    "                except: # Array index error\n",
    "                    pass\n",
    "                \n",
    "                \n",
    "    with rio.open(out_dir + name + '.geotiff', 'w', **raster.profile) as dst:\n",
    "        dst.write(output, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpolation Result\n",
    "<img src=\"https://i.imgur.com/gZSiuIs.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zonal Stats\n",
    "We will now load the block group shapefile and use rasterstats' zonal_stats function to calculate the evaporation data for each block group.\n",
    "\n",
    "Note that this will take a long time for each file because there are ~150,000 block groups!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterstats as rs\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "shape_file = '../../../data/input_file_data/SelectBG_all_land_BGID_final.gpkg'\n",
    "shape_frame = gpd.read_file(shape_file)\n",
    "shape_frame['GEOID10'] = shape_frame['GEOID10'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making ./evap/\n"
     ]
    }
   ],
   "source": [
    "out_dir = './evap/'\n",
    "if not os.path.exists(out_dir):\n",
    "    print('Making', out_dir)\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_statistics = ['mean']\n",
    "\n",
    "for file in glob.glob('./geotiffs/masked_extended_geotiffs/*.geotiff'):\n",
    "    band_number = file[file.rfind('/')+1:file.rfind('.')]\n",
    "    outfile = out_dir + band_number + '.pkl'\n",
    "    \n",
    "    stats = rs.zonal_stats(shape_frame, file, stats=output_statistics, all_touched=True)\n",
    "    frame = pd.DataFrame.from_dict(stats)\n",
    "    frame = frame.join(shape_frame['GEOID10'])\n",
    "    frame.to_pickle(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
