{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget  # Downloading Data\n",
    "from osgeo import gdal  # GDAL\n",
    "import rasterio as rio  # Modifying Raster datasets\n",
    "import geopandas as gpd\n",
    "import rasterstats as rs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import sys, os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget rasterstats --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_vars = ['apcp', 'rhum.2m', 'air.sfc']  # NARR variables we will be downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in extract_vars:  # Make base Directories\n",
    "    if not os.path.exists('./' + var):\n",
    "        os.makedirs('./' + var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in extract_vars:\n",
    "    out_dir = './' + var + '/netcdf/'\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    \n",
    "#   Example: ftp://ftp.cdc.noaa.gov/Datasets/NARR/Dailies/monolevel/air.sfc.2000.nc\n",
    "    for year in range(2000,2019):\n",
    "        dl_url = 'ftp://ftp.cdc.noaa.gov/Datasets/NARR/Dailies/monolevel/' + var + '.' + str(year) + '.nc'\n",
    "        filename = out_dir + var + '.' + str(year) + '.nc'\n",
    "        \n",
    "        wget.download(dl_url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Land Mask\n",
    "wget.download('ftp://ftp.cdc.noaa.gov/Datasets/NARR/time_invariant/land.nc', './land.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to GeoTIFF, Warp to EPSG 4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the NetCDF subdatasets used to access the data in NETCDF form\n",
    "netcdf_subdatasets = {\n",
    "                        'apcp':'apcp',\n",
    "                        'rhum.2m': 'rhum',\n",
    "                        'air.sfc':'air',\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for var in extract_vars:\n",
    "    out_dir = './' + var + '/geotiff/'\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "        \n",
    "        \n",
    "    warp_options = gdal.WarpOptions(options='-t_srs \\\"EPSG:4326\\\" -of GTiff')  # set target spatial project, output type = GeoTIFF\n",
    "    for year in tqdm(glob.glob('./' + var + '/netcdf/*.nc')):  # Do this for all netcdf files\n",
    "        name = year.split('/')[3]\n",
    "        \n",
    "        print('Processing:', name)\n",
    "        ds = gdal.Warp(srcDSOrSrcDSTab='NETCDF:' + year + ':' + netcdf_subdatasets[var], destNameOrDestDS=out_dir + name + '.geotiff', options=warp_options)\n",
    "        ds = None # Flush the file cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp Land Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_options = gdal.WarpOptions(options='-t_srs \\\"EPSG:4326\\\" -of GTiff')\n",
    "ds = gdal.Warp(srcDSOrSrcDSTab='NETCDF:./land.nc:land', destNameOrDestDS='./land.geotiff', options=warp_options)\n",
    "ds = None # Flush the file cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Land Mask\n",
    "#### Import Gdal_Calc script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdal_path = '/opt/conda/bin/'\n",
    "sys.path.insert(0, gdal_path)\n",
    "try:\n",
    "    import gdal_calc\n",
    "except:\n",
    "    print('gdal_calc not found, please specify the path to this file in the cell above')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask_file = './land.geotiff'\n",
    "\n",
    "for var in extract_vars:\n",
    "    out_dir = './' + var + '/masked_daily_geotiff/'\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "        \n",
    "    for file in tqdm(glob.glob('./' + var + '/geotiff/*.geotiff')):\n",
    "        band_count = gdal.Open(file).RasterCount  # Get number of days (bands) in that year's file\n",
    "        \n",
    "        if var != 'apcp': # format for the dot in rhum.2m and air.sfc\n",
    "            year = file[file.rfind('/')+6:-11].split('.')[1]\n",
    "        else: \n",
    "            year = file[file.rfind('/')+6:-11]\n",
    "            \n",
    "        sub_out_dir = out_dir + year + '/'\n",
    "        if not os.path.exists(sub_out_dir):\n",
    "            os.makedirs(sub_out_dir)\n",
    "        \n",
    "        for band in range(1, band_count+1):\n",
    "            outfile = sub_out_dir + str(band) + '.geotiff'\n",
    "            if not os.path.exists(outfile):\n",
    "                gdal_calc.Calc('A*B', A=file, B=mask_file, A_band=band, outfile=outfile, format='GTiff', NoDataValue=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zonal Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_frame = gpd.read_file('./tl_2017_us_county/tl_2017_us_county.shp')\n",
    "shape = shape_frame.to_crs('+proj=longlat +datum=WGS84 +no_defs')\n",
    "shape['GEOID'] = shape['GEOID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for year in range(2000, 2019):\n",
    "    year_dir = './' + var + '/data_NEW_NEW/' + str(year) + '/'\n",
    "    if not os.path.exists(year_dir):\n",
    "        print('Making', year_dir)\n",
    "        os.makedirs(year_dir)\n",
    "\n",
    "    year_files = sorted(glob.glob('./' + var + '/masked_daily_geotiff/' + str(year) + '/*.geotiff'))\n",
    "    print('PROCESSING', len(year_files), 'FILES')\n",
    "\n",
    "    for file in year_files:\n",
    "        name = file[file.rfind('/')+1:file.rfind('.')] # the number of the day (1 for January 1, ..., 365 for December 31)\n",
    "        stats = rs.zonal_stats(shape, file, stats=output_columns, all_touched=True)\n",
    "        frame = pd.DataFrame.from_dict(stats).set_index(shape_frame['GEOID'])\n",
    "        frame.to_pickle(year_dir + name + '.pkl')\n",
    "        print(year_dir + name + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
